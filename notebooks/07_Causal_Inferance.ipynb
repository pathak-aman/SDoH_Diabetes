{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b4d4e9-24b7-44cc-b095-3c0db0e83bb1",
   "metadata": {},
   "source": [
    "HW#3 Causal AI - Group Memebers: Aman Pathak & Aseel Al-Omary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193b304-24bc-41e0-991c-9feccaca8481",
   "metadata": {},
   "source": [
    "#### Recap on our Causal question from last assignment was:\n",
    "\n",
    "What is the causal effect of improved healthcare access (treatment) on diabetes-related health outcomes (outcome), controlling for socioeconomic factors (e.g., income, education), clinical factors (e.g., BMI, blood pressure), and the mediating effects of lifestyle factors (e.g., physical activity, diet) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed2468-35ed-443c-90eb-00bdcca086c1",
   "metadata": {},
   "source": [
    "###  AIPW applied to SDoH and Diabetes Risk\n",
    "To estimate the causal effect of improved healthcare access on diabetes-related health outcomes while accounting for confounding factors, the Augmented Inverse Probability Weighting (AIPW) method is well-suited. \n",
    "Here's how and why AIPW fits this context and how it will be implemented:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc53a3-74a8-4d8a-9d9e-9be7bb66c68b",
   "metadata": {},
   "source": [
    "#### Why AIPW is Suitable\n",
    "- Robustness to Model Misspecification: \n",
    "AIPW provides consistent estimates of the causal effect as long as either the outcome model (predicting diabetes-related health outcomes) or the propensity score model (predicting healthcare access) is correctly specified.\n",
    "\n",
    "- Handling High-Dimensional Covariates: \n",
    "Given the inclusion of various socioeconomic, clinical, and lifestyle factors, AIPW is advantageous as it can efficiently adjust for these covariates, reducing confounding bias. It allows us to control for potential confounders that might simultaneously influence healthcare access and diabetes outcomes.\n",
    "\n",
    "- Flexibility with Heterogeneous Effects: \n",
    "AIPW can accommodate continuous and binary outcomes, making it adaptable to different diabetes-related measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1cf4f7-6054-4703-8096-985fcf5bdfc7",
   "metadata": {},
   "source": [
    "### How AIPW is implemented to our Data\n",
    "- 1- Start by importing dependancies (libraries)\n",
    "- 2- Reading the data to workspace\n",
    "- 3- Defining: treatment, outcome, and covariates (regressors) and preparing them through (Dummy Variable Handling for categorical features and Feature Scaling for numerical features)\n",
    "- 5- Splitting 80% training - 20%testing\n",
    "- 6- DRLearner model inetiation, training and iterative model fitting and evaluation (The DRLearner model is trained and evaluated separately for each dummy treatment variable), to be able to set up the causal forest.\n",
    "- 7-Estimating the Average Treatment Effect (ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4a308-3de4-44ee-b72a-b01ae6345cc5",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7f3c4f-094c-438f-a684-4dcadb3e4fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from econml.dr import DRLearner\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1beb0-d229-4886-bb3e-47c2b68e5ec5",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84d2871-d84e-4989-9bda-4c42d6f7012b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "data = pd.read_csv(\"combined_X_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288203a-47ce-45e4-9d5f-ac361600d04b",
   "metadata": {},
   "source": [
    "Handling Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f281733-b3e4-451b-a243-1fea44f509bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "if data.isnull().sum().any():\n",
    "    print(\"There are missing values in the dataset.\")\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa49e5-f548-46d6-8d5a-6b9435f7fe8d",
   "metadata": {},
   "source": [
    "Managing datatypes and encoding categorical data preparing for later modeling, to avoid the dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047968d9-dfe8-450a-86ce-b8cbeffe7f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# numerical Variables/columns\n",
    "num_cols = [\"BMI\"]\n",
    "# categorical Variables/columns\n",
    "cat_cols = ['Stroke','MentHlth','Education','GenHlth',\n",
    " 'Fruits','PhysActivity','Smoker','DiffWalk','CholCheck',\n",
    " 'PhysHlth','HighBP','Sex', 'HvyAlcoholConsump','Age',\n",
    " 'NoDocbcCost', 'HeartDiseaseorAttack','Income','HighChol',\n",
    " 'Veggies']\n",
    "# Encode categorical columns\n",
    "xf = pd.get_dummies(data[cat_cols])\n",
    "data = pd.concat([data.drop(cat_cols, axis=1), xf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850c51e-c649-4ff2-bd2e-7330553c4b02",
   "metadata": {},
   "source": [
    "### Define Regressors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a7554d-e72e-4908-8712-dcb035b2314b",
   "metadata": {},
   "source": [
    "Regressors are used used in both the propensity score model and the outcome regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21507a4e-8d3d-438e-bf18-dac6db43ba6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressors = num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91aa913-4cf4-41e2-bf92-3def50c27a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add in the dummy names to the list of regressors\n",
    "cat_var_dummy_names = list(xf.columns)\n",
    "regressors = regressors + cat_var_dummy_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ce35d-94ef-4462-99e5-d85b39d42a92",
   "metadata": {},
   "source": [
    " Define: treatment, outcome, and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9b5ed9-1306-479d-bfc3-7bcd6d2c2ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining treatment, outcome, and covariates for our dataset as per to the causal Question\n",
    "treatment = \"AnyHealthcare\"\n",
    "outcome = \"Diabetes_binary\"\n",
    "covariates = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
    "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
    "       'HvyAlcoholConsump', 'NoDocbcCost', 'GenHlth',\n",
    "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65036dcf-ba1c-40e7-b689-5e9cf3feaef0",
   "metadata": {},
   "source": [
    "Define transformed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb0b129-4edd-4081-adb9-246637175bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformed variables using regressors (covarietes after dummies)\n",
    "X = data[regressors]\n",
    "T = data[treatment]  # Ensure this matches the actual column name exactly\n",
    "Y = data[outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5703a3b-3bdf-4fae-b688-40c0b53a7e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34e9767-88a2-4247-b5cd-942ee7c35c7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data splitting: creating training and test datasets\n",
    "- X: This is the feature matrix, which contains the independent predictors excluding the treatment and outcome.\n",
    "- T: This is the treatment variable (healthcare access)\n",
    "- Y: This is the outcome variable, which contains the dependent variable being studied (Diabetes Risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa730d39-db09-440e-b2b5-66ce3f4e8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test = train_test_split(X, T, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3941712f-200e-492b-829e-35d026cf075c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47587ceb-ce6c-4fdd-8fe9-18f26f266578",
   "metadata": {},
   "source": [
    "#### VIF (Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1f431-b39c-47bf-b611-8ed3a72780d8",
   "metadata": {},
   "source": [
    "an optional step: due to multiple warnings we decided to check for Multicollinearity as highly correlated covariates can cause issues with the co-variance matrix. \n",
    "the check for multicollinearity utilized VIF (Variance Inflation Factor) \n",
    "Generally:\n",
    "- A VIF of 1 indicates no correlation between the given predictor and other predictors.\n",
    "- A VIF between 1 and 5 suggests moderate correlation but typically not enough to warrant corrective measures.\n",
    "- A VIF above 5 indicates a high correlation and suggests significant multicollinearity.\n",
    "- A VIF above 10 is often seen as problematic and suggests multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "639f6ab4-4fe7-4bdb-bf7c-9c52128aee86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF:                  feature        VIF\n",
      "0                    BMI  17.772375\n",
      "1                 Stroke   1.126698\n",
      "2               MentHlth   1.462138\n",
      "3              Education  28.107251\n",
      "4                GenHlth  10.655296\n",
      "5                 Fruits   3.032425\n",
      "6           PhysActivity   4.627034\n",
      "7                 Smoker   1.931259\n",
      "8               DiffWalk   1.838034\n",
      "9              CholCheck  21.879450\n",
      "10              PhysHlth   1.999503\n",
      "11                HighBP   2.298462\n",
      "12                   Sex   1.910027\n",
      "13     HvyAlcoholConsump   1.083521\n",
      "14                   Age   9.500974\n",
      "15           NoDocbcCost   1.188276\n",
      "16  HeartDiseaseorAttack   1.289697\n",
      "17                Income  13.830783\n",
      "18              HighChol   2.029529\n",
      "19               Veggies   5.821505\n"
     ]
    }
   ],
   "source": [
    "# Check for multicollinearity using VIF (optional step)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(\"VIF:\", vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee889aa0-69fc-4a11-8214-c08ab0b30cad",
   "metadata": {},
   "source": [
    "Using the above guideline, the features with VIFs above 10 and indicative of high multicollinearity are:\n",
    "(Education, BMI, CholCheck, GenHlth, Income, Age)\n",
    "- Education: VIF = 28.107251\n",
    "- BMI: VIF = 17.772375\n",
    "- CholCheck: VIF = 21.879450\n",
    "- GenHlth: VIF = 10.655296\n",
    "- Income: VIF = 13.830783\n",
    "- Age: VIF = 9.500974 (borderline high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32909fb-b1aa-44cc-b71e-042a15cda25d",
   "metadata": {},
   "source": [
    "Given these results,addressing multicollinearity could include:removing highly correlated features if removing one or any of the features is feasible without losing significant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804cd16-7637-4af4-a0da-4d09e5507b2d",
   "metadata": {},
   "source": [
    "### Scenario_A: Modeling and calculating AIPW without addressing multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9198f9fb-f367-46bf-8e19-fbf2dfbe3437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "propensity_model = LogisticRegression(max_iter=1000)\n",
    "outcome_model = RandomForestClassifier()  # Use classifier for binary outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ec7126a-7940-4b46-b49b-f24a741864af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize DRLearner with discrete_outcome explicitly set to True\n",
    "aipw_model = DRLearner(model_propensity=propensity_model, \n",
    "                       model_regression=outcome_model,\n",
    "                       discrete_outcome=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b63d783-d6ae-4fa1-ab69-baa1e4dd8438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<econml.dr._drlearner.DRLearner at 0x335015190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model again\n",
    "aipw_model.fit(Y_train, T_train, X=X_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b2ad949-ae0c-4eac-9260-8418ef127297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE: [-0.00680782]\n",
      "95% Confidence Interval: (-0.06364846485851786, 0.05003282830570859)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "ate = aipw_model.ate(X_test_scaled)\n",
    "ate_conf_int = aipw_model.ate_interval(X_test_scaled)\n",
    "print(\"Estimated ATE:\", ate)\n",
    "print(\"95% Confidence Interval:\", ate_conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce5f67-7e67-4606-9fe0-156628409139",
   "metadata": {},
   "source": [
    "## Inference Results:\n",
    "\n",
    "a. Estimated ATE: [-0.00680782]\n",
    "This means that, on average, individuals with improved healthcare access have a slightly lower probability of developing diabetes compared to those without improved access. The negative value indicates a decrease in the outcome variable (diabetes) due to the treatment (improved healthcare access).\n",
    " \n",
    "b. 95% Confidence Interval: (-0.06364846485851786, 0.05003282830570859)\n",
    "This represents the interval within which the true average treatment effect is likely to lie with 95% confidence. As it includes zero, we cannot definitively conclude that there is a statistically significant effect of healthcare access on diabetes risk at the 5% significance level\n",
    " \n",
    "c. Interpretation:\n",
    "As the estimated ATE is negative, it does suggest a potential benefit of healthcare access, but its magnitude is very very low. The narrow confidence interval indicates moderate certainty in the estimate.\n",
    " \n",
    "d. Assumption:\n",
    "Overlap: The treatment and control groups must share sufficient similarity in observed characteristics. This ensures that the propensity score model can accurately estimate treatment probabilities for everyone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d462f2-8dd7-4bf3-a52f-21ad57eb8c63",
   "metadata": {},
   "source": [
    "### Scenario_B: Modeling and calculating AIPW addressing multicollinearity by removing highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "599fb4bd-e041-4587-aa18-fd44e7963042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_vif_features = ['BMI', 'CholCheck', 'Education', 'GenHlth', 'Income']\n",
    "revised_columns = [col for col in X.columns if col not in high_vif_features]\n",
    "\n",
    "# Define new features excluding the high VIF features\n",
    "X2 = data[revised_columns]\n",
    "T2 = data[treatment]  # Use multiple binary columns as treatment\n",
    "Y2 = data[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06df1635-fb45-4e82-84aa-a91f9d05cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train2, X_test2, T_train2, T_test2, Y_train2, Y_test2 = train_test_split(X2, T2, Y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82f7e23f-1e93-4be5-9b18-39fdefcb43a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "X_test2_scaled = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22427f72-b556-4325-a5b8-66674b523b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "propensity_model2 = LogisticRegression(max_iter=1000)\n",
    "outcome_model2 = RandomForestClassifier()  # Use classifier for binary outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae41f712-bc95-4b79-bdeb-9b644ba2b11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize DRLearner with discrete_outcome explicitly set to True\n",
    "aipw_model2 = DRLearner(model_propensity=propensity_model2, \n",
    "                       model_regression=outcome_model2,\n",
    "                       discrete_outcome=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c429fd2-eea2-4845-b49a-6e2d61c57076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<econml.dr._drlearner.DRLearner at 0x3806f4c50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model again\n",
    "aipw_model2.fit(Y_train2, T_train2, X=X_train2_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e787767c-3b3e-4b6b-be89-593ef8d616ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE: [-0.01620563]\n",
      "95% Confidence Interval: (-0.05919128508383329, 0.026780019906768857)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "ate2 = aipw_model2.ate(X_test2_scaled)\n",
    "ate_conf_int2 = aipw_model2.ate_interval(X_test2_scaled)\n",
    "print(\"Estimated ATE:\", ate2)\n",
    "print(\"95% Confidence Interval:\", ate_conf_int2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c297887-57bc-417e-9ab8-737c7d5df012",
   "metadata": {},
   "source": [
    "The Estimated ATE for both scinarios is close without removing= [-0.00680782] , with removing= [-0.01620563] , possible reasons might indicate that the negative effect of the treatment on the outcome is slightly stronger when multicollinearity issues are addressed.\n",
    "\n",
    "The difference in ATE estimates between Scenario A and Scenario B, while present, is relatively small. This suggests that multicollinearity might not have had a huge impact on the treatment effect estimation in this case, but addressing it does seem to produce a more stable and slightly adjusted estimate. It is generally advisable to address multicollinearity to ensure the robustness and reliability of causal inference analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2385a-d514-496f-8ef3-796f5773fb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
